{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ2LzvnvZTNiwK2hzJ/agE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleDelliVeneri/DeepFocus/blob/andrea/WandBDeepFocusFirstProof.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuMbYKhJSaus",
        "outputId": "25d901f2-330a-4e6e-8bf8-82178f8d0d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essentials\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, learning_curve, KFold, cross_val_score, StratifiedKFold\n",
        "\n",
        "# Image Libraries\n",
        "from PIL import Image, ImageFilter, ImageStat\n",
        "import random\n",
        "random.seed(42)\n",
        "import imageio\n",
        "import PIL\n",
        "import os\n",
        "import itertools\n",
        "import glob\n",
        "import cv2, glob\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import AxesGrid\n",
        "%matplotlib inline\n",
        "\n",
        "# Ignore excessive warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "metadata": {
        "id": "EZSAzh_Ldp9t"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mmyvLulSdPo",
        "outputId": "8528d6e5-43a3-4bb3-e677-0c43843ec99e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the dataset form Github\n",
        "!git clone https://github.com/lavanyashukla/simpsons-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY3KeVNWctCs",
        "outputId": "15c4782a-b2a1-450e-ab80-bf4529bf649c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'simpsons-dataset'...\n",
            "remote: Enumerating objects: 21934, done.\u001b[K\n",
            "remote: Total 21934 (delta 0), reused 0 (delta 0), pack-reused 21934\u001b[K\n",
            "Receiving objects: 100% (21934/21934), 590.28 MiB | 30.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (42860/42860), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "#from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "oxKdr1lMclTi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key = \"219cf3e455facd673385a920c779226b7ed5f0d3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IE7CwASo2M",
        "outputId": "6f30e2ec-0ff3-40ce-b7df-dbb3268dccc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Visualize images in the dataset\n",
        "# characters = glob.glob('simpsons-dataset/kaggle_simpson_testset/kaggle_simpson_testset/**')\n",
        "# plt.figure(figsize=(10,10))\n",
        "# plt.subplots_adjust(wspace=0, hspace=0)\n",
        "# i = 0\n",
        "# for character in characters[:25]:\n",
        "#     img = cv2.imread(character)\n",
        "#     img = cv2.resize(img, (250, 250))\n",
        "#     plt.axis('off')\n",
        "#     plt.subplot(5, 5, i+1) #.set_title(l) #subplot 5x5 using a for cycle \n",
        "#     plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "#     i += 1"
      ],
      "metadata": {
        "id": "N4cRYOihfqxi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels for the Simpsons characters we're detecting\n",
        "character_names = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
        "        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
        "        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lenny_leonard', 11:'lisa_simpson',\n",
        "        12: 'marge_simpson', 13: 'mayor_quimby',14:'milhouse_van_houten', 15: 'moe_szyslak', \n",
        "        16: 'ned_flanders', 17: 'nelson_muntz', 18: 'principal_skinner', 19: 'sideshow_bob'}\n",
        "img_size = 64\n",
        "num_classes = 20\n",
        "dir = \"simpsons-dataset/simpsons_dataset/simpsons_dataset\"\n",
        "\n",
        "# Load training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for label, name in character_names.items():\n",
        "   list_images = os.listdir(dir+'/'+name)\n",
        "   for image_name in list_images:\n",
        "       image = imageio.imread(dir+'/'+name+'/'+image_name)\n",
        "       X_train.append(cv2.resize(image, (img_size,img_size)))\n",
        "       y_train.append(label)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Split data for cross validation  \n",
        "X_train = X_train[:1000] \n",
        "y_train = y_train[:1000]\n",
        "\n",
        "X_test = X_train[-100:] \n",
        "y_test = y_train[-100:]\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One hot encode the labels (neural nets only like numbers)\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "6KMxEAJDSyBu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6m4fkBJWlN6",
        "outputId": "3f7e3597-679c-4d24-c855-af4cdfcf1057"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.18.87-py2.py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.8/172.8 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.8/dist-packages (from torchio) (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchio) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.8/dist-packages (from torchio) (1.13.1+cu116)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1\n",
            "  Downloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.8/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torchio) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from torchio) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.1->torchio) (4.4.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer[all]->torchio) (7.1.2)\n",
            "Collecting colorama<0.5.0,>=0.4.3\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Downloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting rich<13.0.0,>=10.11.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich<13.0.0,>=10.11.0->typer[all]->torchio) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK, commonmark, shellingham, rich, Deprecated, colorama, torchio\n",
            "Successfully installed Deprecated-1.2.13 SimpleITK-2.2.1 colorama-0.4.6 commonmark-0.9.1 rich-12.6.0 shellingham-1.5.0.post1 torchio-0.18.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BEGIN THE SWEEPS** \n"
      ],
      "metadata": {
        "id": "t7W0_ZclgaK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import torchio as tio #library to load, prepocess augment and patch-based sampling "
      ],
      "metadata": {
        "id": "d8B3dhNhfF5Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'name' : 'CAEALMASweep',\n",
        "    'method' : 'bayes', #grid, random\n",
        "    'metric' : {\n",
        "        'name' : 'val_loss',\n",
        "        'goal' : 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "         # First of all lets put all constant parameters in the config\n",
        "        'dataset' : {\n",
        "            'value' : 'ALMA'\n",
        "        },\n",
        "        'project_name' : {'value' : 'CAEALMASweep'},\n",
        "       \n",
        "        'data_path' : {\n",
        "            'value' : '/lustre/home/mdelliveneri/ALMADL/data/'\n",
        "        },\n",
        "\n",
        "        'output_path': {\n",
        "            'value': '/lustre/home/mdelliveneri/ALMADL/saved_models/'\n",
        "        },\n",
        "        'resume' : {'value' : False},\n",
        "\n",
        "        'epochs': {\n",
        "            'value': 60\n",
        "        },\n",
        "\n",
        "         'dmode': {\n",
        "            'value': 'deconvolver'\n",
        "        },\n",
        "         'parameter': {\n",
        "            'value': 'flux'\n",
        "        },\n",
        "\n",
        "        'num_workers' : {\n",
        "            'value' : 8\n",
        "        },\n",
        "\n",
        "        'weight_decay' : {\n",
        "            'value' : 1e-05\n",
        "        },\n",
        "        \n",
        "        'batch_size': {\n",
        "            'value': 4 \n",
        "        },\n",
        "\n",
        "        'normalize': {\n",
        "            'value': True\n",
        "        },\n",
        "\n",
        "        'channel_names': {\n",
        "            'value' : ['Euclid_H', 'Euclid_J',  'Euclid_Y', 'LSST_g', \n",
        "                  'LSST_i', 'LSST_r', 'LSST_u', 'LSST_y', 'LSST_z']\n",
        "        },\n",
        "\n",
        "        'map_name': {\n",
        "            'value': 'stellarmass'\n",
        "        },\n",
        "        'block_sizes' : {\n",
        "            'value': [16, 32, 64, 128]\n",
        "        },\n",
        "\n",
        "        'oblock_sizes' : {\n",
        "            'value' : [16, 8, 1]\n",
        "        },\n",
        "\n",
        "        'output_kernel_sizes' : {\n",
        "            'value' : [3, 3, 3]\n",
        "        },\n",
        "\n",
        "        'in_channels': {'value': 1},\n",
        "        'out_channels': {'value': 1},\n",
        "\n",
        "        'criterion' : {\n",
        "            'value' : ['L1', 'SSIM']\n",
        "        },\n",
        "        'final_activation' : {\n",
        "            'value' : 'sigmoid'\n",
        "        },\n",
        "\n",
        "        'input_shape' : {\n",
        "            'value' : (256, 256, 128)\n",
        "        },\n",
        "\n",
        "        'preprocess' : {\n",
        "            'value': 'log'\n",
        "        },\n",
        "\n",
        "        'warm_start' : {\n",
        "            'value': True\n",
        "        },\n",
        "\n",
        "        'warm_start_iterations' : {\n",
        "            'value': 10\n",
        "        },\n",
        "\n",
        "        'debug': {'value': False},\n",
        "        'log_rate': {'value': 25},\n",
        "        'preprocess': {'value': None},\n",
        "\n",
        "        \n",
        "        # Then parameters that must tuned\n",
        "\n",
        "        'optimizer': {\n",
        "            'values': ['Adam', 'SGD']\n",
        "        },\n",
        "        'learning_rate': {'max': 0.001, 'min': 0.00001},\n",
        "\n",
        "        \n",
        "        'kernel_sizes' : {\n",
        "            'values': [[(3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)], [(5, 5, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)]]\n",
        "        },\n",
        "        'depths' : {\n",
        "            'values' : [[2, 2, 2, 2], [3, 4, 6, 3], [3, 4, 23, 3]]\n",
        "        },\n",
        "\n",
        "        'hidden_size' : {\n",
        "            'values': [256, 512, 1024]\n",
        "        },\n",
        "        'skip_connections' : {\n",
        "            'values' : [True, False]\n",
        "        },\n",
        "        \n",
        "\n",
        "        'encoder_activation' : {\n",
        "            'values' : ['relu', 'leaky_relu']\n",
        "        },\n",
        "        'decoder_activation' : {\n",
        "            'values' : ['relu',  'leaky_relu']\n",
        "        },\n",
        "        'block' : {\n",
        "            'values' : ['basic', 'bottleneck']\n",
        "        },\n",
        "        'dropout_rate' : {\n",
        "            'values' : [0.0, 0.2, 0.3, 0.4, 0.5]\n",
        "        }   \n",
        "    }\n",
        "\n",
        "}\n",
        "print(\"Hello There!\")\n",
        "print('Starting sweep....')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVBohQO7gwWq",
        "outputId": "fac1cea8-7a8e-4883-e1cd-09780149220c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello There!\n",
            "Starting sweep....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.init(project=\"simpsonsDeepFocus\", entity=\"astroinformatics\")\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"simpsonsDeepFocus\", entity='astroinformatics')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHdzSfI_iC0D",
        "outputId": "16d2e96d-2cf6-4203-805f-d4b473b49573"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: yzuaov7y\n",
            "Sweep URL: https://wandb.ai/astroinformatics/simpsonsDeepFocus/sweeps/yzuaov7y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oP1stPQ6jOR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymqAFDMJxCer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DL_UTILS**"
      ],
      "metadata": {
        "id": "czYnCInkwkx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVw0avZ8xDiY",
        "outputId": "15046769-1f70-43eb-c1f1-48506f1fb1bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl (569 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from kornia) (23.0)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from kornia) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.9.1->kornia) (4.4.0)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from tqdm import tqdm\n",
        "import astropy \n",
        "from astropy.io import fits\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import random\n",
        "import pandas as pd\n",
        "from kornia.losses import SSIMLoss\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "from torchvision.utils import make_grid\n",
        "import torchio as tio\n",
        "from torch.autograd import Variable\n",
        "import multiprocessing as mp\n",
        "from time import time\n",
        "import torch.distributed as dist\n",
        "import datetime\n",
        "import matplotlib\n",
        "from matplotlib import gridspec"
      ],
      "metadata": {
        "id": "BkH40NJVwprN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### think later how to set devices and training different arch. in parallel\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "liv6v5SOxJcu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- DEEEP LEARNING FUNCTIONS AND CLASSES ----------------- #\n",
        "from math import exp\n",
        "\n",
        "#print a list of exp(something) of lenght windows size\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1) #add a dimention to the second position\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0) #mm = torch matrix mult  = mult column x row (becames 2d matrix)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())  #contiguous = saved tensor in contiguous memory; Variable (same as Tensor) is deprecated\n",
        "    return window\n",
        "\n",
        "def create_window_3D(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t())\n",
        "    _3D_window = _1D_window.mm(_2D_window.reshape(1, -1)).reshape(window_size, window_size, window_size).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_3D_window.expand(channel, 1, window_size, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return 1 - ssim_map.mean()\n",
        "    else:\n",
        "        return 1 - ssim_map.mean(1).mean(1).mean(1)\n",
        "    \n",
        "def _ssim3D(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv3d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv3d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv3d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv3d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv3d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return 1 - ssim_map.mean()\n",
        "    else:\n",
        "        return 1 - ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)"
      ],
      "metadata": {
        "id": "_-GJfuFgxcRN"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SSIM3D(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM3D, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window_3D(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window_3D(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim3D(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
        "\n",
        "def ssim3D(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _, _) = img1.size()\n",
        "    window = create_window_3D(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim3D(img1, img2, window, window_size, channel, size_average)\n",
        "\n",
        "class batch_act(nn.Module):\n",
        "    def __init__(self, in_c, act):\n",
        "        super(batch_act, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_c)\n",
        "        self.act = activation_func(act)\n",
        "    def forward(self, inputs):\n",
        "        x = self.act(inputs)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "class Conv1dAuto(nn.Conv1d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "      super().__init__(*args, **kwargs) \n",
        "      self.padding = (self.kernelsize[0]//2)\n",
        "\n",
        "class Conv2dAuto(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2)  # dynamic add padding based on the kernel_size\n",
        "\n",
        "class Conv3dAuto(nn.Conv3d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2, self.kernel_size[2] // 2)  # dynamic add padding based on the kernel_size\n",
        "\n",
        "class ConvTran1dAuto(nn.ConvTranspose1d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  ((self.kernel_size[0] - 1) // 2, (self.kernel_size[1] - 1) // 2)\n",
        "\n",
        "class ConvTran2dAuto(nn.ConvTranspose2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  ((self.kernel_size[0] - 1) // 2, (self.kernel_size[1] - 1) // 2)  # dynamic add padding based on the kernel_size\n",
        "\n",
        "class ConvTran3dAuto(nn.ConvTranspose3d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  ((self.kernel_size[0] - 1) // 2, (self.kernel_size[1] - 1) // 2, (self.kernel_size[2] - 1) // 2)  # dynamic add padding based on the kernel_size\n",
        "\n",
        "def activation_func(activation):\n",
        "    return  nn.ModuleDict([\n",
        "        ['relu', nn.ReLU(inplace=True)],\n",
        "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
        "        ['selu', nn.SELU(inplace=True)],\n",
        "        ['none', nn.Identity()],\n",
        "        ['sigmoid', nn.Sigmoid()],\n",
        "        ['tanh', nn.Tanh()],\n",
        "    ])[activation]\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, activation='relu', dim=2):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
        "        self.dim = dim\n",
        "        self.blocks = nn.Identity()\n",
        "        self.activate = activation_func(activation)\n",
        "        self.shortcut = nn.Identity()   \n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
        "        x = self.blocks(x)\n",
        "        x += residual\n",
        "        x = self.activate(x)\n",
        "        return x\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.out_channels\n",
        "\n",
        "class ResNetResidualBlock(ResidualBlock):\n",
        "    def __init__(self, in_channels, out_channels, conv, expansion=1, downsampling=1, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
        "        if self.dim ==1:\n",
        "          self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                      stride=self.downsampling, bias=False),\n",
        "                nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
        "        elif self.dim == 2:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                      stride=self.downsampling, bias=False),\n",
        "                nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
        "        elif self.dim == 3:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                        stride=self.downsampling, bias=False),\n",
        "                nn.BatchNorm3d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
        "        \n",
        "    @property\n",
        "    def expanded_channels(self):\n",
        "        return self.out_channels * self.expansion\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.expanded_channels\n",
        "\n",
        "def conv_bn(in_channels, out_channels, conv, dim=2, *args, **kwargs):\n",
        "    if dim ==1:\n",
        "        return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm1d(out_channels))\n",
        "    elif dim == 2:\n",
        "        return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))\n",
        "    elif dim == 3:\n",
        "        return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm3d(out_channels))\n",
        "\n",
        "class ResNetBasicBlock(ResNetResidualBlock):\n",
        "    \"\"\"\n",
        "    Basic ResNet block composed by two layers of 3x3conv/batchnorm/activation\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, conv, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, conv,  *args, **kwargs)\n",
        "        if self.dim == 1:\n",
        "          self.blocks = nn.Sequential(\n",
        "            conv_bn(self.in_channels, self.out_channels, self.conv, self.dim, bias=False, stride=self.downsampling),\n",
        "            activation_func(self.activation),\n",
        "            conv_bn(self.out_channels, self.expanded_channels, self.conv, bias=False),\n",
        "            )\n",
        "        if self.dim == 2:\n",
        "            self.blocks = nn.Sequential(\n",
        "                conv_bn(self.in_channels, self.out_channels, self.conv, self.dim, bias=False, stride=self.downsampling),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.expanded_channels, self.conv, self.dim, bias=False),\n",
        "            )\n",
        "        elif self.dim == 3:\n",
        "            self.blocks = nn.Sequential(\n",
        "                conv_bn(self.in_channels, self.out_channels, self.conv, dim=self.dim, bias=False, stride=self.downsampling),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.expanded_channels, self.conv, dim=self.dim, bias=False),)\n",
        "    \n",
        "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, conv, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, conv, expansion=4, *args, **kwargs)\n",
        "        if self.dim == 1:\n",
        "            self.blocks = nn.Sequential(\n",
        "                conv_bn(self.in_channels, self.out_channels, self.conv, self.dim, kernel_size=1),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.out_channels, self.conv, self.dim, stride=self.downsampling),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.expanded_channels, self.conv, self.dim, kernel_size=1),\n",
        "            )\n",
        "        elif self.dim == 2:\n",
        "            self.blocks = nn.Sequential(\n",
        "                conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.out_channels, self.conv, stride=self.downsampling),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
        "            )\n",
        "        elif self.dim == 3:\n",
        "            self.blocks = nn.Sequential(\n",
        "                conv_bn(self.in_channels, self.out_channels, self.conv,  dim=self.dim, kernel_size=1),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.out_channels, self.conv,  dim=self.dim, stride=self.downsampling),\n",
        "                activation_func(self.activation),\n",
        "                conv_bn(self.out_channels, self.expanded_channels, self.conv, dim=self.dim,  kernel_size=1),\n",
        "            )\n",
        "\n",
        "class ResNetLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A ResNet layer composed by `n` blocks stacked one after the other\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, block=ResNetBasicBlock, n=1, dim=2, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
        "        downsampling = 2 if in_channels != out_channels else 1\n",
        "        if dim == 1:\n",
        "            conv = partial(Conv1dAuto, kernel_size=kernel_size)\n",
        "        elif dim == 2:\n",
        "            conv = partial(Conv2dAuto, kernel_size=kernel_size)\n",
        "        elif dim == 3:\n",
        "            conv = partial(Conv3dAuto, kernel_size=kernel_size)\n",
        "        self.blocks = nn.Sequential(\n",
        "            block(in_channels , out_channels, conv, *args, **kwargs, downsampling=downsampling, dim=dim),\n",
        "            *[block(out_channels * block.expansion, \n",
        "                    out_channels, conv, downsampling=1, *args, **kwargs, dim=dim) for _ in range(n - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return x\n",
        "\n",
        "class ResNetEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet encoder composed by increasing different layers with increasing features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], kernel_sizes=[3, 3, 3, 3], \n",
        "                 depths=[2,2,2,2], hidden_size=1024,\n",
        "                 activation='relu', block=ResNetBasicBlock, input_shape=(256, 256),\n",
        "                 skip_connections=False, \n",
        "                 debug=False,\n",
        "                 dmode='deconvolver',\n",
        "                 dropout_rate=0.0,\n",
        "                 *args,**kwargs):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.blocks_sizes = blocks_sizes\n",
        "        self.depths = depths\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.input_shape = input_shape\n",
        "        self.hidden_size = hidden_size\n",
        "        self.skip_connections = skip_connections\n",
        "        self.debug = debug\n",
        "        self.dmode = dmode\n",
        "        self.dropout_rate = dropout_rate\n",
        "        if block == ResNetBasicBlock:\n",
        "            self.expansion = 1\n",
        "        elif block == ResNetBottleNeckBlock:\n",
        "            self.expansion = 4\n",
        "        if len(self.input_shape) == 1:\n",
        "            self.dim = 1\n",
        "            self.gate = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "                nn.BatchNorm1d(self.blocks_sizes[0]),\n",
        "                activation_func(activation),\n",
        "                nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "            )\n",
        "            self.dense = nn.Sequential(\n",
        "                    nn.Linear(blocks_sizes[-1] * input_shape[0] // 2**(len(depths) + 1) * input_shape[1] // 2**(len(depths) + 1), self.hidden_size),\n",
        "                    activation_func(activation))\n",
        "        elif len(self.input_shape) == 2:\n",
        "            self.dim = 2\n",
        "            self.gate = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "                nn.BatchNorm2d(self.blocks_sizes[0]),\n",
        "                activation_func(activation),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "            )\n",
        "            self.dense = nn.Sequential(\n",
        "                    nn.Linear(blocks_sizes[-1] * input_shape[0] // 2**(len(depths) + 1) * input_shape[1] // 2**(len(depths) + 1), self.hidden_size),\n",
        "                    activation_func(activation))\n",
        "        elif len(self.input_shape) == 3:\n",
        "            self.dim = 3\n",
        "            self.gate = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "                nn.BatchNorm3d(self.blocks_sizes[0]),\n",
        "                activation_func(activation),\n",
        "                nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "            )\n",
        "            if self.dropout_rate > 0.0:\n",
        "                self.dense = nn.Sequential(\n",
        "                    nn.Dropout(dropout_rate),\n",
        "                    nn.Linear(blocks_sizes[-1] * self.expansion * input_shape[0] // 2**(len(depths) + 1) * input_shape[1] // 2**(len(depths) + 1)* input_shape[2] // 2**(len(depths) + 1), self.hidden_size),\n",
        "                    activation_func(activation))\n",
        "            else:\n",
        "                self.dense = nn.Sequential(\n",
        "                    nn.Linear(blocks_sizes[-1] * self.expansion * input_shape[0] // 2**(len(depths) + 1) * input_shape[1] // 2**(len(depths) + 1)* input_shape[2] // 2**(len(depths) + 1), self.hidden_size),\n",
        "                    activation_func(activation))\n",
        "        self.in_out_block_sizes_kernels = list(zip(blocks_sizes, blocks_sizes[1:], kernel_sizes))\n",
        "        self.blocks = nn.ModuleList([ \n",
        "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], kernel_sizes[0], n=depths[0], activation=activation, \n",
        "                        block=block,  *args, **kwargs, dim=self.dim),\n",
        "            *[ResNetLayer(in_channels * block.expansion, \n",
        "                          out_channels, kernel_size, n=n, activation=activation, \n",
        "                          block=block, *args, **kwargs, dim=self.dim) \n",
        "              for (in_channels, out_channels, kernel_size), n in zip(self.in_out_block_sizes_kernels, depths[1:])]       \n",
        "        ])\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.gate(x)\n",
        "        if self.debug:\n",
        "            print('Encoder Gate: ', x.shape)\n",
        "        if self.skip_connections:\n",
        "            skip = []\n",
        "        for i, block in zip(np.arange(len(self.blocks)), self.blocks):\n",
        "            x = block(x)\n",
        "            if self.debug:\n",
        "                print('After Block {}: '.format(i), x.shape)\n",
        "            if self.skip_connections:\n",
        "                skip.append(x)\n",
        "        if self.dmode == 'deconvolver':\n",
        "            x = torch.flatten(x, start_dim=1)\n",
        "            x = self.dense(x)\n",
        "            if self.debug:\n",
        "                print('Encoder Dense: ', x.shape)\n",
        "        if self.skip_connections:\n",
        "            return x, skip[:-1]\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "class Interpolate(nn.Module): # Down/up samples the input to either the given size or the given scale_factor\n",
        "    def __init__(self, scale_factor, mode, align_corners=False):\n",
        "        super(Interpolate, self).__init__()\n",
        "        self.interp = F.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode # the algo to interpolate \n",
        "        self.align_corners = align_corners\n",
        "    def forward(self, x):\n",
        "        x = self.interp(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "        return x\n",
        "\n",
        "class ResNetDecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A ResNet decoder layer composed by upsampling and concatenating with a skip connection\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, block=ResNetBasicBlock, dim=2, activation='relu', *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.activation = activation\n",
        "        if self.dim == 1:\n",
        "            self.interpolate = Interpolate(scale_factor=2, mode='linear', align_corners=True) \n",
        "            tconv = partial(ConvTran1dAuto, kernel_size=kernel_size)\n",
        "            self.upsample = nn.Sequential(\n",
        "                tconv(in_channels, out_channels, stride=2, padding=1, output_padding=1),\n",
        "                #nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=2, padding=1, output_padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                activation_func(activation)\n",
        "            )\n",
        "            conv = partial(Conv2dAuto, kernel_size=kernel_size)\n",
        "\n",
        "        if self.dim == 2:\n",
        "            self.interpolate = Interpolate(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            tconv = partial(ConvTran2dAuto, kernel_size=kernel_size)\n",
        "            self.upsample = nn.Sequential(\n",
        "                tconv(in_channels, out_channels, stride=2, padding=1, output_padding=1),\n",
        "                #nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=2, padding=1, output_padding=1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                activation_func(activation)\n",
        "            )\n",
        "            conv = partial(Conv2dAuto, kernel_size=kernel_size)\n",
        "        elif self.dim == 3:\n",
        "            self.interpolate = Interpolate(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "            tconv = partial(ConvTran3dAuto, kernel_size=kernel_size)\n",
        "            self.upsample = nn.Sequential(\n",
        "                #nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=2, padding=1, output_padding=1),\n",
        "                tconv(in_channels, out_channels, stride=2, padding=1, output_padding=1),\n",
        "                nn.BatchNorm3d(out_channels),\n",
        "                activation_func(activation)\n",
        "            )\n",
        "            conv = partial(Conv3dAuto, kernel_size=kernel_size)\n",
        "        self.block = block(in_channels + out_channels, out_channels, conv, *args, **kwargs, \n",
        "                      dim=self.dim, activation=self.activation)\n",
        "        self.oblock = block(in_channels, out_channels, conv, *args, **kwargs, \n",
        "                      dim=self.dim, activation=self.activation)\n",
        "    def forward(self, x, skip=None):\n",
        "        #print('Deconder Input ',  x.shape)\n",
        "        i = self.interpolate(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, i], dim=1)\n",
        "        #print('Deconder After Upsample ',  x.shape)\n",
        "        x = self.block(x)\n",
        "        #print('Print After Double Channel ', x.shape)\n",
        "        if skip != None:\n",
        "            #print('Before concatenate: ',x.shape, skip.shape)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            #print('After concatenate: ',x.shape)\n",
        "            #print(self.block.in_channels, x.shape[1])\n",
        "            x = self.oblock(x)\n",
        "        return x\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, dim,  shape):\n",
        "        super(View, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        new_shape = list(input.shape)[:self.dim] + list(self.shape) + list(input.shape)[self.dim+1:]\n",
        "        return input.view(*new_shape)\n",
        "\n",
        "nn.Unflatten = View\n",
        "\n",
        "class ResNetDecoder(nn.Module):\n",
        "    def __init__(self, output_channels=1, blocks_sizes=[512, 256, 128, 64], \n",
        "                 oblocks_sizes=[64, 32, 1],\n",
        "                 kernel_sizes=[3, 3, 3, 3],\n",
        "                 okernel_sizes=[3, 3, 3],\n",
        "                 hidden_size=1024,\n",
        "                 activation='relu',\n",
        "                 final_activation='sigmoid',\n",
        "                 block=ResNetBasicBlock, input_shape=(256, 256),\n",
        "                 skip_connections=False,\n",
        "                 debug=False,\n",
        "                 *args,**kwargs):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.blocks_sizes = blocks_sizes\n",
        "        self.oblocks_sizes = oblocks_sizes\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.input_shape = input_shape\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_channels = output_channels\n",
        "        self.skip_connections = skip_connections\n",
        "        self.activation = activation\n",
        "        \n",
        "        self.debug = debug\n",
        "        if block == ResNetBasicBlock:\n",
        "            self.expansion = 1\n",
        "        elif block == ResNetBottleNeckBlock:\n",
        "            self.expansion = 4\n",
        "        self.in_out_block_sizes_kernels = list(zip(blocks_sizes[1:], blocks_sizes[2:], kernel_sizes[1:]))\n",
        "        self.out_block_sizes_kernels = list(zip(oblocks_sizes, oblocks_sizes[1:], okernel_sizes))\n",
        "        print('Expansion factor: ', self.expansion)\n",
        "        \n",
        "        if len(self.input_shape) == 1:\n",
        "            self.dim = 2\n",
        "            self.dense = nn.Sequential(\n",
        "                    nn.Linear(self.hidden_size, blocks_sizes[0] * self.expansion * input_shape[0] // 2**(len(self.blocks_sizes) + 1) * input_shape[1] // 2**(len(self.blocks_sizes) + 1)),\n",
        "                    activation_func(activation))\n",
        "\n",
        "            self.unflatten = nn.Unflatten(dim=1, shape=(blocks_sizes[0] * self.expansion, \n",
        "                                input_shape[0] // 2**(len(self.blocks_sizes) + 1), \n",
        "                                input_shape[1] // 2**(len(self.blocks_sizes) + 1)))\n",
        "            self.blocks = nn.ModuleList([ \n",
        "                ResNetDecoderLayer(blocks_sizes[0] * self.expansion, blocks_sizes[1], kernel_sizes[0], block=block, *args, **kwargs, \n",
        "                                    dim=self.dim, activation=self.activation),\n",
        "                *[ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels * self.expansion, kernel_size, block=block, *args, **kwargs, \n",
        "                                 dim=self.dim, activation=self.activation) \n",
        "                 for (in_channels, out_channels, kernel_size) in self.in_out_block_sizes_kernels]       \n",
        "            ])\n",
        "            self.oblocks = nn.ModuleList([ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels, kernel_size, block=block, *args, **kwargs, \n",
        "                                 dim=self.dim, activation=self.activation) \n",
        "              for (in_channels, out_channels, kernel_size) in self.out_block_sizes_kernels])\n",
        "            self.out = nn.Sequential(\n",
        "                nn.Conv1d(self.oblocks_sizes[-1] * self.expansions, self.output_channels, kernel_size=1, padding=0),\n",
        "                activation_func(final_activation))\n",
        "        elif len(self.input_shape) == 2:\n",
        "            self.dim = 2\n",
        "            self.dense = nn.Sequential(\n",
        "                    nn.Linear(self.hidden_size, blocks_sizes[0] * self.expansion * input_shape[0] // 2**(len(self.blocks_sizes) + 1) * input_shape[1] // 2**(len(self.blocks_sizes) + 1)),\n",
        "                    activation_func(activation))\n",
        "\n",
        "            self.unflatten = nn.Unflatten(dim=1, shape=(blocks_sizes[0] * self.expansion, \n",
        "                                input_shape[0] // 2**(len(self.blocks_sizes) + 1), \n",
        "                                input_shape[1] // 2**(len(self.blocks_sizes) + 1)))\n",
        "            self.blocks = nn.ModuleList([ \n",
        "                ResNetDecoderLayer(blocks_sizes[0] * self.expansion, blocks_sizes[1], kernel_sizes[0], block=block, *args, **kwargs, \n",
        "                                    dim=self.dim, activation=self.activation),\n",
        "                *[ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels * self.expansion, kernel_size, block=block, *args, **kwargs, \n",
        "                                 dim=self.dim, activation=self.activation) \n",
        "                 for (in_channels, out_channels, kernel_size) in self.in_out_block_sizes_kernels]       \n",
        "            ])\n",
        "            self.oblocks = nn.ModuleList([ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels, kernel_size, block=block, *args, **kwargs, \n",
        "                                 dim=self.dim, activation=self.activation) \n",
        "              for (in_channels, out_channels, kernel_size) in self.out_block_sizes_kernels])\n",
        "            self.out = nn.Sequential(\n",
        "                nn.Conv2d(self.oblocks_sizes[-1] * self.expansions, self.output_channels, kernel_size=1, padding=0),\n",
        "                activation_func(final_activation))\n",
        "        elif len(self.input_shape) == 3:\n",
        "            self.dim = 3\n",
        "            self.dense = nn.Sequential(\n",
        "                nn.Linear(self.hidden_size, blocks_sizes[0] * self.expansion * input_shape[0] // 2**(len(self.blocks_sizes) + 1) * input_shape[1] // 2**(len(self.blocks_sizes) + 1) * input_shape[2] // 2**(len(self.blocks_sizes) + 1)),\n",
        "                activation_func(activation))\n",
        "            self.unflatten = nn.Unflatten(dim=1, shape=(blocks_sizes[0] * self.expansion,\n",
        "                                            input_shape[0] // 2**(len(self.blocks_sizes) + 1),\n",
        "                                            input_shape[1] // 2**(len(self.blocks_sizes) + 1),\n",
        "                                            input_shape[2] // 2**(len(self.blocks_sizes) + 1)))\n",
        "            self.blocks = nn.ModuleList([ \n",
        "                ResNetDecoderLayer(blocks_sizes[0] * self.expansion, blocks_sizes[1], kernel_sizes[0], block=block, *args, **kwargs, dim=self.dim),\n",
        "                *[ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels , kernel_size, block=block, *args, **kwargs, dim=self.dim) \n",
        "                 for (in_channels, out_channels, kernel_size) in self.in_out_block_sizes_kernels]       \n",
        "            ])\n",
        "            self.oblocks = nn.ModuleList([ResNetDecoderLayer(in_channels * self.expansion, \n",
        "                                 out_channels, kernel_size, block=block, *args, **kwargs, dim=self.dim) \n",
        "              for (in_channels, out_channels, kernel_size) in self.out_block_sizes_kernels])\n",
        "            self.out = nn.Sequential(\n",
        "                    nn.Conv3d(self.oblocks_sizes[-1] * self.expansion, self.output_channels, kernel_size=1, padding=0),\n",
        "                    activation_func(final_activation))\n",
        "\n",
        "    \n",
        "    def forward(self, x, skips=[None]):\n",
        "        x = self.dense(x)\n",
        "        if self.debug:\n",
        "            print('After Decoder Dense: ', x.shape)\n",
        "        x = self.unflatten(x)\n",
        "        if self.debug:\n",
        "            print('After Unflattering: ', x.shape)\n",
        "        if self.skip_connections is True:\n",
        "            skips = skips[::-1]\n",
        "        else:\n",
        "            skip = [None] * len(self.blocks)\n",
        "        for i,  block, skip in zip(np.arange(len(self.blocks)), self.blocks, skips):\n",
        "            if self.debug and skip != None:\n",
        "                print('Before Decoder Block: ', x.shape, skip.shape)\n",
        "            elif self.debug:\n",
        "                print('Before Decoder Block: ', x.shape)\n",
        "            x = block(x, skip)\n",
        "            if self.debug:\n",
        "                print('After Decoder Block {}: '.format(i), x.shape)\n",
        "        for i,  block in zip(np.arange(len(self.oblocks)), self.oblocks):\n",
        "            x = block(x, None)\n",
        "            if self.debug:\n",
        "                print('After Decoder Out Block {}: '.format(i), x.shape)\n",
        "        x = self.out(x)\n",
        "        if self.debug:\n",
        "            print('After Out: ', x.shape)\n",
        "        return x\n",
        "\n",
        "class ResNetRegressor(nn.Module):\n",
        "    def __init__(self, in_features, n_hidden, n_classes, activation='relu', classification=False, debug=False, dropout_rate=0.0, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.debug = debug\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        if classification is True:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, n_hidden),\n",
        "                activation_func(activation),\n",
        "                nn.Linear(n_hidden, n_classes),\n",
        "                nn.Softmax(dim=1))\n",
        "        else:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(in_features, n_hidden),\n",
        "                activation_func(activation),\n",
        "                nn.Linear(n_hidden, n_classes))\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        if self.debug:\n",
        "            print('After Avg Pooling: ', x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.debug:\n",
        "            print('After Flattening: ', x.shape)\n",
        "        x = self.fc(x)\n",
        "        if self.debug:\n",
        "            print('After FC: ', x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BluDC2OFx-EL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepFocus(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, blocks_sizes=[64, 128, 256, 512],\n",
        "                 oblocks_sizes=[64, 32, 1],\n",
        "                 encoder_kernel_sizes=[3, 3, 3, 3],\n",
        "                 depths = [2, 2, 2, 2],\n",
        "                 decoder_kernel_sizes=[3, 3, 3, 3],\n",
        "                 output_kernel_sizes=[3, 3, 3],\n",
        "                 hidden_size=1024,\n",
        "                 encoder_activation='relu',\n",
        "                 decoder_activation='relu',\n",
        "                 encoder_block=ResNetBasicBlock,\n",
        "                 decoder_block=ResNetBasicBlock,\n",
        "                 final_activation='sigmoid',\n",
        "                 input_shape=(256, 256),\n",
        "                 skip_connections=False,\n",
        "                 dmode='deconvolver',\n",
        "                 debug=False,\n",
        "                 dropout_rate=0.0, \n",
        "                 *args,**kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.depths = depths\n",
        "        self.encoder_blocks_sizes = blocks_sizes\n",
        "        self.decoder_blocks_sizes = blocks_sizes[::-1]\n",
        "        self.oblocks_sizes = oblocks_sizes\n",
        "        self.encoder_kernel_sizes = encoder_kernel_sizes\n",
        "        self.decoder_kernel_sizes = decoder_kernel_sizes\n",
        "        self.output_kernel_sizes = output_kernel_sizes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.encoder_activation = encoder_activation\n",
        "        self.decoder_activation = decoder_activation\n",
        "        self.encoder_block = encoder_block\n",
        "        self.decoder_block = decoder_block\n",
        "        self.final_activation = final_activation\n",
        "        self.input_shape = input_shape\n",
        "        self.skip_connections = skip_connections\n",
        "        self.debug = debug\n",
        "        self.dmode = dmode\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.encoder = ResNetEncoder(in_channels=self.in_channels, \n",
        "                                     blocks_sizes=self.encoder_blocks_sizes,\n",
        "                                     kernel_sizes=self.encoder_kernel_sizes,\n",
        "                                     depths=self.depths,\n",
        "                                     hidden_size=self.hidden_size,\n",
        "                                     activation=self.encoder_activation,\n",
        "                                     block=self.encoder_block,\n",
        "                                     input_shape=self.input_shape,\n",
        "                                     skip_connections=self.skip_connections,\n",
        "                                     debug=self.debug,\n",
        "                                     dmode=self.dmode,\n",
        "                                     dropout_rate = self.dropout_rate\n",
        "                                     )\n",
        "        if self.dmode == 'deconvolver':\n",
        "            print('Building Deconvolver')\n",
        "            self.decoder = ResNetDecoder(output_channels=self.out_channels,\n",
        "                                     blocks_sizes=self.decoder_blocks_sizes,\n",
        "                                     oblocks_sizes=self.oblocks_sizes,\n",
        "                                        kernel_sizes=self.decoder_kernel_sizes,\n",
        "                                        okernel_sizes=self.output_kernel_sizes,\n",
        "                                        hidden_size=self.hidden_size,\n",
        "                                        activation=self.decoder_activation,\n",
        "                                        final_activation=self.final_activation,\n",
        "                                        block=self.decoder_block,\n",
        "                                        input_shape=self.input_shape,\n",
        "                                        skip_connections=self.skip_connections,\n",
        "                                        debug=self.debug)\n",
        "        elif self.dmode == 'regressor':\n",
        "            print('Building Regressor')\n",
        "            self.decoder = ResNetRegressor(in_features=self.encoder_blocks_sizes[-1]  * self.encoder_block.expansion,\n",
        "                                           n_hidden=self.hidden_size,\n",
        "                                           n_classes=self.out_channels,\n",
        "                                           activation=self.decoder_activation,\n",
        "                                           classification=False,\n",
        "                                           debug=self.debug, \n",
        "                                           dropout_rate=self.dropout_rate)\n",
        "        elif self.dmode == 'classifier':\n",
        "            print('Building Classifier')\n",
        "            self.decoder = ResNetRegressor(in_features=self.encoder_blocks_sizes[-1]  * self.encoder_block.expansion,\n",
        "                                           n_hidden=self.hidden_size,\n",
        "                                           n_classes=self.out_channels,\n",
        "                                           activation=self.decoder_activation,\n",
        "                                           classification=True,\n",
        "                                           debug=self.debug,\n",
        "                                           dropout_rate=self.dropout_rate)\n",
        "    def forward(self, x):\n",
        "        if self.skip_connections:\n",
        "            lat, skips = self.encoder(x)\n",
        "            x = self.decoder(lat, skips)\n",
        "            return x\n",
        "        else:\n",
        "            lat = self.encoder(x)\n",
        "            x = self.decoder(lat)\n",
        "            return x"
      ],
      "metadata": {
        "id": "lY_VdTP3yF7o"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-ndBBtYwpS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3WKUA-l6Qsq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}